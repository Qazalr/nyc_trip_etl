# NYC Taxi Trip ETL Pipeline ðŸ—½ðŸš•

This project demonstrates an ETL pipeline using **Apache Airflow + Docker** to process and transform New York City yellow taxi trip data for 2019.

---

## ðŸ“¦ Dataset

We use the **Yellow Taxi Trip Records for 2019**.

ðŸ“‚ **Dataset Source:**  
[Kaggle - NYC Yellow Taxi 2019 Dataset](https://www.kaggle.com/code/dhruvildave/starter-new-york-city-taxi-trips?select=yellow_tripdata_2019)

â¬‡ï¸ After downloading, place the `.csv` files inside: /opt/airflow/data/yellow_tripdata_2019/

---

## ðŸ› ï¸ Setup Instructions

### ðŸ”§ Prerequisites

- [Docker](https://docs.docker.com/get-docker/)
- [Docker Compose](https://docs.docker.com/compose/install/)

---

### ðŸš€ Step-by-Step

1. **Clone the repository**

```bash
git clone https://github.com/Qazalr/nyc_trip_etl.git
cd nyc_trip_etl

**Download Airflow Docker Compose template**
curl -LfO 'https://airflow.apache.org/docs/apache-airflow/3.0.3/docker-compose.yaml'
mkdir -p ./dags ./logs ./plugins ./config
echo -e "AIRFLOW_UID=$(id -u)\nAIRFLOW_GID=0" > .env

**start airflow**
docker-compose up

**Access Airflow UI**

Go to: http://localhost:8080
	â€¢	Username: airflow
	â€¢	Password: airflow



ðŸ§  DAGs Overview
	â€¢	nyc_trip_etl_dag.py: Main DAG for managing the pipeline.
	â€¢	load_csv_to_postgres.py: Loads and cleans CSV files into PostgreSQL.
	â€¢	transform_trips.py: Applies transformations (e.g., amount_per_passenger column).

**PostgreSQL Access**

to access run 
docker exec -it nyc_trip_etl-postgres-1 psql -U airflow -d nyc_trips
Then you can run:
SELECT COUNT(*) FROM raw_trips;
SELECT * FROM raw_trips LIMIT 10;

Notes
	â€¢	Data is inserted in chunks to avoid memory overflow.
	â€¢	Files already loaded are tracked in the loaded_files table.
	â€¢	Rows with null values are removed.
	â€¢	New column amount_per_passenger is added during transformation.

â¸»
ðŸ›‘ Shutting Down

To stop all containers:

docker-compose down